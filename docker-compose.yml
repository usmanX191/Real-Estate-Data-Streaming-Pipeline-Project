# version: "3.8" # Make sure you are using version 3.8

# services:
#   zookeeper:
#     image: confluentinc/cp-zookeeper:7.5.0
#     container_name: zookeeper
#     ports:
#       - "2181:2181"
#     environment:
#       ZOOKEEPER_CLIENT_PORT: 2181
#       ZOOKEEPER_TICK_TIME: 2000
#     healthcheck:
#       test: ["CMD", "nc", "-z", "localhost", "2181"]
#       interval: 10s
#       timeout: 10s
#       retries: 5

#   kafka:
#     image: confluentinc/cp-kafka:7.5.0
#     container_name: kafka
#     depends_on:
#       - zookeeper # Remove "condition: service_healthy" if it's not working
#     ports:
#       - "9092:9092"
#     environment:
#       KAFKA_BROKER_ID: 1
#       KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
#       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#     networks:
#       - elk-net

#   # Remaining services...

# networks:
#   elk-net:
#     driver: bridge

# volumes:
#   es_data:
#     driver: local
# version: "3.9"

# services:
#   # Zookeeper
#   zk:
#     image: confluentinc/cp-zookeeper:7.4.0
#     hostname: zk
#     container_name: zk
#     ports:
#       - "2181:2181"
#     environment:
#       ZOOKEEPER_CLIENT_PORT: 2181
#       ZOOKEEPER_TICK_TIME: 2000
#     healthcheck:
#       test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
#       interval: 10s
#       timeout: 5s
#       retries: 5
#     networks:
#       - datamasterylab

#   # Kafka Broker
#   kafka-broker:
#     image: confluentinc/cp-kafka:7.4.0
#     hostname: kafka-broker
#     depends_on:
#       zk:
#         condition: service_healthy
#     ports:
#       - "9092:9092"
#       - "9101:9101"
#     environment:
#       KAFKA_BROKER_ID: 1
#       KAFKA_ZOOKEEPER_CONNECT: "zk:2181"
#       KAFKA_LISTENERS: INSIDE://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
#       KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka-broker:29092,OUTSIDE://localhost:9092
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
#       KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
#       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#     networks:
#       - datamasterylab
#     healthcheck:
#       test: ["CMD", "kafka-topics", "--zookeeper", "zk:2181", "--list"]
#       interval: 10s
#       timeout: 5s
#       retries: 5

#   # Confluent Control Center
#   control-center:
#     image: confluentinc/cp-enterprise-control-center:7.4.0
#     hostname: control-center
#     container_name: control-center
#     depends_on:
#       kafka-broker:
#         condition: service_healthy
#     ports:
#       - "9021:9021"
#     environment:
#       CONTROL_CENTER_BOOTSTRAP_SERVERS: "kafka-broker:29092"
#       CONTROL_CENTER_REPLICATION_FACTOR: 1
#       CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
#       CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
#     healthcheck:
#       test: ["CMD", "curl", "-f", "http://localhost:9021/health"]
#       interval: 30s
#       timeout: 105s
#       retries: 5
#     networks:
#       - datamasterylab

#   # Elasticsearch
#   elasticsearch:
#     image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
#     environment:
#       - discovery.type=single-node
#       - xpack.security.enabled=false # Disable security for simplicity
#       - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
#     ports:
#       - "9200:9200"
#     networks:
#       - datamasterylab

#   # Kibana
#   kibana:
#     image: docker.elastic.co/kibana/kibana:8.10.2
#     environment:
#       ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
#     ports:
#       - "5601:5601"
#     networks:
#       - datamasterylab
#     depends_on:
#       - elasticsearch

#   # Kafka Connect
#   kafka-connect:
#     image: confluentinc/cp-kafka-connect:7.4.0
#     hostname: kafka-connect
#     container_name: kafka-connect
#     ports:
#       - "8083:8083"
#     environment:
#       CONNECT_BOOTSTRAP_SERVERS: "kafka-broker:29092"
#       CONNECT_REST_PORT: 8083
#       CONNECT_GROUP_ID: "kafka-connect-elasticsearch"
#       CONNECT_CONFIG_STORAGE_TOPIC: "docker-connect-configs"
#       CONNECT_OFFSET_STORAGE_TOPIC: "docker-connect-offsets"
#       CONNECT_STATUS_STORAGE_TOPIC: "docker-connect-status"
#       CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#       CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#       CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
#       CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
#       CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=WARN"
#       CONNECT_PLUGIN_PATH: "/usr/share/java"
#       CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
#     depends_on:
#       - kafka-broker
#     volumes:
#       - ./kafka-plugins:/usr/share/java
#     networks:
#       - datamasterylab

# networks:
#   datamasterylab:
version: "3"
x-spark-common: &spark-common
  image: bitnami/spark:3.5.2
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
  networks:
    - datamasterylab
services:
  zk:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zk
    container_name: zk
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datamasterylab

  kafka-broker:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka-broker
    depends_on:
      zk:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zk:2181"
      KAFKA_LISTENERS: INSIDE://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka-broker:29092,OUTSIDE://localhost:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:29092,PLAINTEXT_HOST://localhost:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      # KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: "false"
      CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"
    networks:
      - datamasterylab
    healthcheck:
      test: ["CMD", "bash", "-c", "nc -z localhost 9092"]
      interval: 10s
      timeout: 5s
      retries: 5
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.0
    hostname: control-center
    container_name: control-center
    depends_on:
      kafka-broker:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: "kafka-broker:29092"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONFLUENT_METRICS_ENABLE: "false"
      PORT: 9021
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9021/health"]
      interval: 30s
      timeout: 105s
      retries: 5
    networks:
      - datamasterylab

  spark-master:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
  spark-worker: &spark-worker-image
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077
  spark-worker-2:
    <<: *spark-worker-image
  spark-worker-3:
    <<: *spark-worker-image
  cassandra_db:
    image: cassandra:latest
    container_name: cassandra
    hostname: cassandra
    ports:
      - "9042:9042"
    environment:
      - MAX_HEAP_SIZE=512M
      - HEAP_NEWSIZE=100M
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    networks:
      - datamasterylab
networks:
  datamasterylab:
